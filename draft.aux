\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Bouwmans2014}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}pixels-based methods}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}region-based approach}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Deep learning methods}{2}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces It is hard to separate the foreground pixels from the background precisely in a time sequence.}}{2}{figure.1}}
\newlabel{variation_chart}{{1}{2}{It is hard to separate the foreground pixels from the background precisely in a time sequence}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}VARIATION TRANSFORMATION}{2}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}BACKGROUND SUBTRACTION VIA DEEP VARIATION TRANSFORMATION}{3}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Fully convolutional networks can efficiently learn to make dense predictions for per-pixel tasks like semantic segmentation.}}{4}{figure.2}}
\newlabel{flow_chart}{{2}{4}{Fully convolutional networks can efficiently learn to make dense predictions for per-pixel tasks like semantic segmentation}{figure.2}{}}
\newlabel{piecewise_fg}{{8}{5}{BACKGROUND SUBTRACTION VIA DEEP VARIATION TRANSFORMATION}{equation.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experiments}{5}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The qualitative evaluation of the proposed method. All the results is followed in the CDnet 2014.}}{6}{figure.3}}
\newlabel{results_chart}{{3}{6}{The qualitative evaluation of the proposed method. All the results is followed in the CDnet 2014}{figure.3}{}}
\bibstyle{IEEEtran}
\bibdata{ref}
\bibcite{Bouwmans2014}{1}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces The performance comparison of the proposed approach and some state-of-the-art algorithms on the video sequences from different categories in CDnet 2014.}}{7}{table.1}}
\newlabel{tab1}{{I}{7}{The performance comparison of the proposed approach and some state-of-the-art algorithms on the video sequences from different categories in CDnet 2014}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The performance comparison of the proposed approach and some classical methods and deep-based method DBMF .}}{7}{table.2}}
\newlabel{tab2}{{II}{7}{The performance comparison of the proposed approach and some classical methods and deep-based method DBMF }{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces The performance comparison of the proposed approach and some state-of-the-art algorithms on the video sequences from different categories in CAMO-UOW.}}{7}{table.3}}
\newlabel{tab3}{{III}{7}{The performance comparison of the proposed approach and some state-of-the-art algorithms on the video sequences from different categories in CAMO-UOW}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{7}{section.6}}
\@writefile{toc}{\contentsline {section}{References}{7}{section*.1}}
